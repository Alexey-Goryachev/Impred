# -*- coding: utf-8 -*-
"""YASO_cifar_10_model.ipynb"

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pBJkl5mj1roO3vXOB_EatI7ACYqr2FmV

This code implements the training and evaluation of a neural network for image classification using the CIFAR-10 dataset. Starting with the utilization of a pre-trained VGG16 model for feature extraction, the code involves building and training a model with added fully connected layers, evaluating its performance on test data, and unfreezing the top layers of VGG16 for further training. It then includes the construction of a modified model with some unfrozen top layers, training this model, and evaluating its effectiveness. The code also involves saving the trained model and visualizing training results using plots.
"""

# Imports

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras

from keras.applications.vgg16 import VGG16
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.optimizers import Adam
from keras.utils import to_categorical, plot_model
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.datasets import cifar10

from sklearn.metrics import classification_report

# Verify the version
print('Packages version: \n')
print(tf.__name__, tf.__version__)
print(np.__name__, np.__version__)
print(pd.__name__, pd.__version__)

# Presettings

num_classes = 10
filepath = "weights.h5"
batch_size = 128
epochs = 50

# Loading the dataset

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Shape cheecing

print(x_train.shape)
print(x_test.shape)

# Defining array. Each item of array represent integer value of labels. 10 item for 10 integer label
class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']

# Inspect the data in the array
index = 8
plt.imshow(x_train[index], cmap=plt.cm.binary)
plt.colorbar()
plt.show()
print(f'Class ID: {y_train[index]} and Class name: {class_names[y_train[index][0]]}')

# Display the first 25 images from traing set
plt.figure(figsize=(25, 25))
for i in range(100):
  plt.subplot(10, 10, i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(x_train[i], cmap=plt.cm.binary)
  plt.xlabel(f'{y_train[i]} {class_names[y_train[i][0]]}')
plt.show()

# Normalization of data and transformation of labels into categorical ones. Pixel value of the image falls between 0 to 255

x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# One hot encoding of the labels

y_train=to_categorical(y_train, num_classes)
y_test=to_categorical(y_test, num_classes)

# Define the Convolutional Neural Network

conv_base = VGG16(weights='imagenet',
                  include_top=False,
                  input_shape=(32, 32, 3))

# Model creation
model = Sequential()
model.add(conv_base)  # Додавання попередньо навченої моделі

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(10, activation='softmax'))

conv_base.trainable = False

# Summary model
model.summary()

# Plot model graph
plot_model(model, 'model.png')

# Compile the model

model.compile(loss='categorical_crossentropy',
              optimizer=Adam(learning_rate=0.0001),
              metrics=['accuracy'])

# Training model

model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          validation_data=(x_test, y_test))

# Unfreeze all layers of the previously trained VGG16 model
conv_base.trainable = True

model.compile(loss='categorical_crossentropy',
              optimizer=Adam(learning_rate=0.0001),
              metrics=['accuracy'])

# Retraining the model
model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          validation_data=(x_test, y_test))

# Evaluation of the model on test data
loss, accuracy = model.evaluate(x_test, y_test)
print("Test Accuracy: {:.2f}%".format(accuracy * 100))

# Obtaining model predictions on test data
y_pred = model.predict(x_test)

# Classification report
report = classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1))
print(report)

"""The model retraining process, conceptualized by Andrew Chychur, involves:

*  Unfreezing Layers: Selected layers of the pre-trained VGG16 model are unfrozen.
*   Creating a Modified Model: A new model is constructed by adding additional layers on top of the unfrozen VGG16 base.
*  Compiling the Model: The modified model is compiled with appropriate optimizer, loss function, and metrics.
*  Training the Model: The modified model is trained on the CIFAR-10 dataset.
*  Evaluation: The model's performance is evaluated on the test dataset.

This process fine-tunes the pre-trained VGG16 model on CIFAR-10, aiming to enhance its performance for the specific task.

"""

conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))

conv_base.trainable = True


layer_list = ["block4_conv1", "block5_conv1"]
for layer in conv_base.layers:
    if layer.name in layer_list:
        set_trainable = True
    else:
        layer.trainable = False


modified_model = Sequential([
   model,
   Flatten(),
   Dense(256, activation="relu"),
   Dense(10, activation="softmax"),
])

# Compile and training model
modified_model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy'])


history = modified_model.fit(
    x_train, y_train, epochs=50, verbose=1, batch_size=128, validation_split=0.2
)

# Отримання передбачень моделі на тестових даних
y_pred_m = modified_model.predict(x_test)
# Отримання класифікаційного звіту
report = classification_report(y_test.argmax(axis=1), y_pred_m.argmax(axis=1))
print(report)

# Save model
model.save("weights-cifar10.h5")

y_hat = model.predict(x_test)

# Plot a random sample of 10 test images, their predicted labels and ground truth
figure = plt.figure(figsize=(20, 8))
for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):
    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])
    # Display each image
    ax.imshow(np.squeeze(x_test[index]))
    predict_index = np.argmax(y_hat[index])

    true_index = np.argmax(y_test[index].astype(int))
    # Set the title for each image
    ax.set_title("{} ({})".format(class_names[predict_index],
                                  class_names[true_index]),
                                  color=("green" if predict_index == true_index else "red"))

# Plot results
pd.DataFrame(history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1)
plt.show()

# Show results
results = modified_model.evaluate(x_test, y_test)
print(results)